{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e62de99",
   "metadata": {},
   "source": [
    "MEGA PROJECT 1: JARVIS - VOICE-ACTIVATED VIRTUAL ASSISTANT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db61d80",
   "metadata": {},
   "source": [
    ". Voice Recognition\n",
    "\n",
    "• Utilizes the speech_recognition library to listen for and recognize voice commands.\n",
    "\n",
    "• Activates upon detecting the wake word \"Jarvis.\"\n",
    "\n",
    "• Text-to-Speech\n",
    "\n",
    "• Converts text to speech using pyttsx3 for local conversion.\n",
    "\n",
    "• Uses gTTS (Google Text-to-Speech) and pygame for playback.\n",
    "\n",
    "• Web Browsing.\n",
    "\n",
    "• Opens websites like Google, Facebook, YouTube, and LinkedIn based on voice commands.\n",
    "\n",
    "• Music Playback\n",
    "\n",
    "• Interfaces with a musicLibrary module to play songs via web links.\n",
    "\n",
    "• News Fetching\n",
    "\n",
    "• Fetches and reads the latest news headlines using NewsAPI.\n",
    "\n",
    "• OpenAI Integration\n",
    "\n",
    "• Handles complex queries and generates responses using OpenAI's GPT-3.5-turbo.\n",
    "\n",
    "• Acts as a general virtual assistant similar to Alexa or Google Assistant.\n",
    "\n",
    "• Activates upon detecting the wake word \"Jarvis.\"\n",
    "\n",
    "• Text-to-Speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7adaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "websites = {\n",
    "    'Google': 'https://www.google.com',\n",
    "    'GitHub': 'https://www.github.com',\n",
    "    'Stack Overflow': 'https://stackoverflow.com',\n",
    "    'Wikipedia': 'https://www.wikipedia.org',\n",
    "    'YouTube': 'https://www.youtube.com'\n",
    "}\n",
    "\n",
    "songs = {\n",
    "    'adakaari': 'https://music.youtube.com/watch?v=6iZ9l3LuSnM&list=OLAK5uy_n-NE0EpQjxokH9NvLp1FZoEkjYZHjOKVQ',\n",
    "    'pukaar': 'https://music.youtube.com/watch?v=LkBhVnQvRyI&list=OLAK5uy_n-NE0EpQjxokH9NvLp1FZoEkjYZHjOKVQ',   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b83b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                # --MAIN CODE BELOW--\n",
    "\n",
    "# import necessary libraries\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import webbrowser\n",
    "import requests\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# initialize the recognizer and text-to-speech engine\n",
    "r = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[1].id)\n",
    "\n",
    "# tts function\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# test websites dictionary\n",
    "websites = {\n",
    "    'Google': 'https://www.google.com',\n",
    "    'GitHub': 'https://www.github.com',\n",
    "    'Stack Overflow': 'https://stackoverflow.com',\n",
    "    'Wikipedia': 'https://www.wikipedia.org',\n",
    "    'YouTube': 'https://www.youtube.com'\n",
    "}\n",
    "\n",
    "# test songs dictionary\n",
    "songs = {\n",
    "    'adakari': 'https://music.youtube.com/watch?v=6iZ9l3LuSnM&list=OLAK5uy_n-NE0EpQjxokH9NvLp1FZoEkjYZHjOKVQ',\n",
    "    'pukar': 'https://music.youtube.com/watch?v=LkBhVnQvRyI&list=OLAK5uy_n-NE0EpQjxokH9NvLp1FZoEkjYZHjOKVQ',   \n",
    "    'sorry' : 'https://music.youtube.com/watch?v=v16qZcBllUU&list=LM'\n",
    "}\n",
    "\n",
    "def process_ai(command):                    #AI processing function using Google Gemini API\n",
    "    client = genai.Client(api_key=#use your own api)\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-3-flash-preview\",\n",
    "        config=types.GenerateContentConfig(\n",
    "            system_instruction=\"You are a Virtual Assistant doing general tasks like Alexa and Google Assistant, give short responses.\",\n",
    "        ),\n",
    "        contents=command\n",
    "    )\n",
    "\n",
    "    return response.text\n",
    "\n",
    "def process_command(c):\n",
    "    print(c)\n",
    "    if 'open google' in c.lower():              #opening websites\n",
    "        speak(\"Opening Google\")\n",
    "        webbrowser.open(websites['Google'])\n",
    "    elif 'open github' in c.lower():\n",
    "        speak(\"Opening GitHub\")\n",
    "        webbrowser.open(websites['GitHub'])\n",
    "    elif 'open stack overflow' in c.lower():\n",
    "        speak(\"Opening Stack Overflow\")\n",
    "        webbrowser.open(websites['Stack Overflow'])\n",
    "    elif 'open wikipedia' in c.lower():\n",
    "        speak(\"Opening Wikipedia\")\n",
    "        webbrowser.open(websites['Wikipedia'])\n",
    "    elif 'open youtube' in c.lower():\n",
    "        speak(\"Opening YouTube\")\n",
    "        webbrowser.open(websites['YouTube'])\n",
    "    elif 'play adakari' in c.lower():           #playing songs\n",
    "        speak(\"Playing Adakari\")\n",
    "        webbrowser.open(songs['adakari'])\n",
    "    elif 'play pukar' in c.lower():\n",
    "        speak(\"Playing Pukar\")\n",
    "        webbrowser.open(songs['pukar'])\n",
    "    elif 'play sorry' in c.lower():\n",
    "        speak(\"Playing Sorry\")\n",
    "        webbrowser.open(songs['sorry'])\n",
    "    elif 'news' in c.lower():                  #fetching news through newsapi\n",
    "        url = #use your own api\n",
    "        params = {\n",
    "            \"country\": \"us\",\n",
    "            \"category\": \"science\",\n",
    "            \"apiKey\": #use your own api\n",
    "        }\n",
    "        response = requests.get(url, params=params)\n",
    "        data = response.json()\n",
    "\n",
    "        for article in data.get(\"articles\", []):\n",
    "            speak(article.get(\"title\"))\n",
    "    else:                                     #AI processing for other commands\n",
    "        output = process_ai(c)\n",
    "        print(output)\n",
    "        speak(output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    speak(\"Initializing Jarvis...\")\n",
    "    \n",
    "    while True: \n",
    "\n",
    "        try:\n",
    "            with sr.Microphone() as source:\n",
    "                print(\"Listening...\")\n",
    "                audio = r.listen(source)\n",
    "        # listens for wake word(command) \"Jarvis\"\n",
    "            word = r.recognize_google(audio)\n",
    "            if (word.lower() == \"jarvis\"):\n",
    "                speak(\"Yes\")\n",
    "                 # listen for further commands\n",
    "                with sr.Microphone() as source:\n",
    "                    print(\"JARVIS ACTIVE\\nListening for command...\")\n",
    "                    audio = r.listen(source)\n",
    "                    # process the command\n",
    "                    command = r.recognize_google(audio)\n",
    "                    process_command(command)\n",
    "\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Google Speech Recognition could not understand audio\")\n",
    "        except sr.RequestError as e:\n",
    "            print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
